{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\berkt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\berkt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.22.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\berkt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\berkt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\berkt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\berkt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\berkt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\berkt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\berkt\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas numpy scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "\n",
    "true=True\n",
    "false=False\n",
    "\n",
    "DTYPE_DICT = {\"INCIDENT_TYPE_DESC\":\"uint16\",\"UNITS_ONSCENE\":\"uint8\",\"TOTAL_INCIDENT_DURATION\":\"uint16\",\"ACTION_TAKEN1_DESC\":\"int16\",\"ACTION_TAKEN2_DESC\":\"int16\",\"ACTION_TAKEN3_DESC\":\"int16\",\"PROPERTY_USE_DESC\":\"int16\",\"BOROUGH_DESC\":\"uint8\",\"SEASON\":\"uint8\",\"TIME_OF_DAY\":\"uint8\",\"WEEKDAY\":\"uint8\"}\n",
    "DROP_COLUMNS = [\"IM_INCIDENT_KEY\",\"FIRE_BOX\", \"ARRIVAL_DATE_TIME\", \"LAST_UNIT_CLEARED_DATE_TIME\", \"HIGHEST_LEVEL_DESC\", \"STREET_HIGHWAY\", \"ZIP_CODE\", \"FLOOR\", \"CO_DETECTOR_PRESENT_DESC\", \"FIRE_ORIGIN_BELOW_GRADE_FLAG\", \"STORY_FIRE_ORIGIN_COUNT\", \"FIRE_SPREAD_DESC\", \"DETECTOR_PRESENCE_DESC\", \"AES_PRESENCE_DESC\", \"STANDPIPE_SYS_PRESENT_FLAG\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data from the split CSV files; in doing so, filter out all rows which do not have one of our input variables, and drop all columns we're not using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1 of 3:..................; Finished file 1\n",
      "Processing file 2 of 3:..................; Finished file 2\n",
      "Processing file 3 of 3:..................; Finished file 3\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCIDENT_TYPE_DESC</th>\n",
       "      <th>UNITS_ONSCENE</th>\n",
       "      <th>TOTAL_INCIDENT_DURATION</th>\n",
       "      <th>ACTION_TAKEN1_DESC</th>\n",
       "      <th>ACTION_TAKEN2_DESC</th>\n",
       "      <th>ACTION_TAKEN3_DESC</th>\n",
       "      <th>PROPERTY_USE_DESC</th>\n",
       "      <th>BOROUGH_DESC</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TIME_OF_DAY</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>735</td>\n",
       "      <td>2</td>\n",
       "      <td>763</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>735</td>\n",
       "      <td>2</td>\n",
       "      <td>1920</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1108</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>429</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>651</td>\n",
       "      <td>2</td>\n",
       "      <td>743</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>999</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INCIDENT_TYPE_DESC  UNITS_ONSCENE  TOTAL_INCIDENT_DURATION  \\\n",
       "0                 300              1                     2355   \n",
       "1                 735              2                      763   \n",
       "2                 735              2                     1920   \n",
       "3                 555              1                     1108   \n",
       "4                 651              2                      743   \n",
       "\n",
       "   ACTION_TAKEN1_DESC  ACTION_TAKEN2_DESC  ACTION_TAKEN3_DESC  \\\n",
       "0                   0                   0                   0   \n",
       "1                  86                   0                   0   \n",
       "2                  86                   0                   0   \n",
       "3                  45                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   PROPERTY_USE_DESC  BOROUGH_DESC  SEASON  TIME_OF_DAY  WEEKDAY  HOUR  MONTH  \\\n",
       "0                999             4       0            0        2     0      1   \n",
       "1                999             2       0            0        2     0      1   \n",
       "2                999             3       0            0        2     0      1   \n",
       "3                429             1       0            0        2     0      1   \n",
       "4                999             2       0            0        2     0      1   \n",
       "\n",
       "   YEAR  \n",
       "0  2020  \n",
       "1  2020  \n",
       "2  2020  \n",
       "3  2020  \n",
       "4  2020  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pud_filt(row):\n",
    "    x = row[\"PROPERTY_USE_DESC\"].split(\" \")[0]\n",
    "    if x == \"NNN\":\n",
    "        return -1\n",
    "    if x == \"UUU\":\n",
    "        return 999\n",
    "    return x\n",
    "\n",
    "def itd_filt(row):\n",
    "    # print(row)\n",
    "    return re.sub('[^0-9]','', row[\"INCIDENT_TYPE_DESC\"].split(\" \")[0])\n",
    "\n",
    "def idt_filt(row):\n",
    "    x = row[\"INCIDENT_DATE_TIME\"]\n",
    "    s = datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p')\n",
    "    return time.mktime(s.timetuple())\n",
    "\n",
    "def extract_season(row):\n",
    "    # 0 = Winter (Dec-Feb)\n",
    "    # 1 = Spring (Mar-May)\n",
    "    # 2 = Summer (June-Aug)\n",
    "    # 3 = Fall (Sep-Nov)\n",
    "    x = row[\"INCIDENT_DATE_TIME\"]\n",
    "    s = datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p').timetuple()\n",
    "    if s.tm_mon < 3 or s.tm_mon == 12:\n",
    "        return 0\n",
    "    elif s.tm_mon < 6:\n",
    "        return 1\n",
    "    elif s.tm_mon < 9:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def extract_tod(row):\n",
    "    # 0 = midnight-6am\n",
    "    # 1 = 6am-noon\n",
    "    # 2 = noon-6pm\n",
    "    # 3 = 6pm-midnight\n",
    "    x = row[\"INCIDENT_DATE_TIME\"]\n",
    "    s = datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p').timetuple()\n",
    "    if s.tm_hour < 6:\n",
    "        return 0\n",
    "    elif s.tm_hour < 12:\n",
    "        return 1\n",
    "    elif s.tm_hour < 18:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def extract_weekday(row):\n",
    "    # 0 = monday, 6=sunday\n",
    "    x = row[\"INCIDENT_DATE_TIME\"]\n",
    "    s = datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p').timetuple()\n",
    "    return s.tm_wday\n",
    "\n",
    "\n",
    "\n",
    "def extract_hour(row):\n",
    "    # 0 - 24 hrs\n",
    "    x = row[\"INCIDENT_DATE_TIME\"]\n",
    "    s = datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p').timetuple()\n",
    "    return s.tm_hour\n",
    "\n",
    "def extract_month(row):\n",
    "    # 0 - 12\n",
    "    x = row[\"INCIDENT_DATE_TIME\"]\n",
    "    s = datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p').timetuple()\n",
    "    return s.tm_mon\n",
    "\n",
    "def extract_year(row):\n",
    "    # 2013-2018, i think\n",
    "    # 2014-2017 just to be safe\n",
    "    x = row[\"INCIDENT_DATE_TIME\"]\n",
    "    s = datetime.strptime(x, '%m/%d/%Y %I:%M:%S %p').timetuple()\n",
    "    return s.tm_year\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "data = None\n",
    "for i in range(3):\n",
    "    print(\"Processing file {} of 3:\".format(i+1),end=\"\")\n",
    "    x = pd.read_csv(\"NewCSVs/file{}.csv\".format(i+1), low_memory=false)\n",
    "    print(\".\",end=\"\")\n",
    "    x.drop(DROP_COLUMNS, axis=1, inplace=True)\n",
    "    print(\".\",end=\"\")\n",
    "    x.dropna(axis=0, subset=[\"INCIDENT_TYPE_DESC\", \"INCIDENT_DATE_TIME\", \"BOROUGH_DESC\", \"PROPERTY_USE_DESC\"], inplace=True)\n",
    "    print(\".\",end=\"\")\n",
    "    x.fillna(0, inplace=True)\n",
    "    print(\".\",end=\"\")\n",
    "    \n",
    "    x[\"BOROUGH_DESC\"] = x.apply(lambda row : int(row[\"BOROUGH_DESC\"][0]), axis=1)\n",
    "    print(\".\",end=\"\")\n",
    "    x[\"ACTION_TAKEN1_DESC\"] = x.apply(lambda row : int(str(row[\"ACTION_TAKEN1_DESC\"]).split(\" \")[0]), axis=1)\n",
    "    print(\".\",end=\"\")\n",
    "    x[\"ACTION_TAKEN2_DESC\"] = x.apply(lambda row : int(str(row[\"ACTION_TAKEN2_DESC\"]).split(\" \")[0]) if str(row[\"ACTION_TAKEN2_DESC\"]) != \"nan\" else -1, axis=1)\n",
    "    print(\".\",end=\"\")\n",
    "    x[\"ACTION_TAKEN3_DESC\"] = x.apply(lambda row : int(str(row[\"ACTION_TAKEN3_DESC\"]).split(\" \")[0]) if str(row[\"ACTION_TAKEN3_DESC\"]) != \"nan\" else -1, axis=1)\n",
    "    print(\".\",end=\"\")\n",
    "    x[\"INCIDENT_TYPE_DESC\"] = x.apply(lambda row : itd_filt(row), axis=1)\n",
    "    print(\".\",end=\"\")\n",
    "    x[\"PROPERTY_USE_DESC\"] = x.apply(lambda row : pud_filt(row), axis=1)\n",
    "    print(\".\",end=\"\")\n",
    "    x[\"SEASON\"] = x.apply(lambda row : extract_season(row), axis=1)\n",
    "    print(\".\",end=\"\")\n",
    "    x[\"TIME_OF_DAY\"] = x.apply(lambda row : extract_tod(row), axis=1)\n",
    "    print(\".\",end=\"\")\n",
    "    x[\"WEEKDAY\"] = x.apply(lambda row : extract_weekday(row), axis=1)\n",
    "    print(\".\",end=\"\")\n",
    "\n",
    "    x[\"HOUR\"] = x.apply(lambda row : extract_hour(row), axis=1)\n",
    "    print(\".\",end=\"\")\n",
    "    x[\"MONTH\"] = x.apply(lambda row : extract_month(row), axis=1)\n",
    "    print(\".\",end=\"\")\n",
    "    x[\"YEAR\"] = x.apply(lambda row : extract_year(row), axis=1)\n",
    "    print(\".\",end=\"\")\n",
    "\n",
    "    x.drop([\"INCIDENT_DATE_TIME\"], axis=1, inplace=True)\n",
    "    print(\".\",end=\"\")\n",
    "\n",
    "    x = x.astype(DTYPE_DICT)\n",
    "    print(\".\",end=\"\")\n",
    "    if data is None:\n",
    "        data = x\n",
    "    else:\n",
    "        data = pd.concat([data,x])\n",
    "    print(\"; Finished file {}\".format(i+1))\n",
    "\n",
    "data = data.astype(DTYPE_DICT)\n",
    "print(\"Done.\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save validation data to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"validate.csv.gzip\",compression=\"gzip\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop extra columns\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"validate.csv.gzip\",compression=\"gzip\",dtype=DTYPE_DICT)\n",
    "data.head(10)\n",
    "\n",
    "print(\"Drop extra columns\")\n",
    "data.drop([\"HOUR\"], axis=1, inplace=True)\n",
    "data.drop([\"MONTH\"], axis=1, inplace=True)\n",
    "data.drop([\"YEAR\"], axis=1, inplace=True)\n",
    "data = data.astype(DTYPE_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin validation by using training models from 2013 to mid 2018 on 2020 and 2021 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting UOS with new data\n",
      "Bayesian UOS MAE: 0.5933835770008786\n",
      "Predicting TID with new data\n",
      "Bayesian TID MAE: 726.6111395841277\n",
      "Predicting AT1 with new data\n",
      "Ridge AT1 Accuracy: 0.8863529333362952\n",
      "Predicting AT2 with new data\n",
      "Ridge AT2 Accuracy: 0.8945798253992936\n",
      "Predicting AT3 with new data\n",
      "Ridge AT3 Accuracy: 0.9591154452762289\n"
     ]
    }
   ],
   "source": [
    "def predict(df, model_dict):\n",
    "    res = []\n",
    "    for i,row in df.iterrows():\n",
    "        itype = int(row.INCIDENT_TYPE_DESC)\n",
    "        pud = int(row.PROPERTY_USE_DESC)\n",
    "        if not itype in model_dict.keys() or not pud in model_dict[itype].keys():\n",
    "            # This combination was not in the training data! return 0\n",
    "            res.append(0)\n",
    "            continue\n",
    "        df = pd.DataFrame(data=[list(row)], columns=df.columns)\n",
    "        res.append(model_dict[itype][pud].predict(df[[\"BOROUGH_DESC\",\"SEASON\",\"TIME_OF_DAY\",\"WEEKDAY\"]])[0])\n",
    "    return res\n",
    "\n",
    "# -----------------------------UNITS ONSCENE---------------------------------------\n",
    "\n",
    "uos_mdl_dict = {}\n",
    "with open('uos_dict_bayesian.pickle','rb') as file:\n",
    "    uos_mdl_dict = pickle.load(file)\n",
    "\n",
    "print(\"Predicting UOS with new data\")\n",
    "res = predict(data, uos_mdl_dict)\n",
    "mae1 = mean_absolute_error(data.UNITS_ONSCENE,res)\n",
    "print(\"Bayesian UOS MAE:\", mae1)\n",
    "\n",
    "# -------------------------TOTAL INCIDENT DURATION---------------------------------\n",
    "\n",
    "tid_mdl_dict = {}\n",
    "with open('tid_dict_bay.pickle','rb') as file:\n",
    "    tid_mdl_dict = pickle.load(file)\n",
    "\n",
    "print(\"Predicting TID with new data\")\n",
    "res = predict(data, tid_mdl_dict)\n",
    "mae2 = mean_absolute_error(data.TOTAL_INCIDENT_DURATION,res)\n",
    "print(\"Bayesian TID MAE:\", mae2)\n",
    "\n",
    "# --------------------------------ACTION 1----------------------------------------\n",
    "\n",
    "at1_mdl_dict = {}\n",
    "with open('at1_dict_ridge.pickle','rb') as file:\n",
    "    at1_mdl_dict = pickle.load(file)\n",
    "\n",
    "print(\"Predicting AT1 with new data\")\n",
    "res = predict(data, at1_mdl_dict)\n",
    "mae3 = accuracy_score(data.ACTION_TAKEN1_DESC,res)\n",
    "print(\"Ridge AT1 Accuracy:\", mae3)\n",
    "\n",
    "# --------------------------------ACTION 2----------------------------------------\n",
    "\n",
    "at2_mdl_dict = {}\n",
    "with open('at2_dict_ridge.pickle','rb') as file:\n",
    "    at2_mdl_dict = pickle.load(file)\n",
    "\n",
    "print(\"Predicting AT2 with new data\")\n",
    "res = predict(data, at2_mdl_dict)\n",
    "mae4 = accuracy_score(data.ACTION_TAKEN2_DESC,res)\n",
    "print(\"Ridge AT2 Accuracy:\", mae4)\n",
    "\n",
    "# --------------------------------ACTION 3----------------------------------------\n",
    "\n",
    "at3_mdl_dict = {}\n",
    "with open('at3_dict_ridge.pickle','rb') as file:\n",
    "    at3_mdl_dict = pickle.load(file)\n",
    "\n",
    "print(\"Predicting AT3 with new data\")\n",
    "res = predict(data, at3_mdl_dict)\n",
    "mae5 = accuracy_score(data.ACTION_TAKEN3_DESC,res)\n",
    "print(\"Ridge AT3 Accuracy:\", mae5)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f2633a0dd9fad194999ffc17b7b93627efd4bccf6144e14bc5fef7dfd0c6355"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
